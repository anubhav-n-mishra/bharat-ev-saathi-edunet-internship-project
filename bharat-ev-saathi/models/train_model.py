"""
Advanced EV Recommendation Model Training
==========================================
Trains a deep neural network using Keras/TensorFlow for EV recommendations.
Produces optimized H5 model with hyperparameter tuning.

Features:
- Deep Neural Network with multiple hidden layers
- Hyperparameter optimization
- Cross-validation
- Feature engineering
- Model evaluation metrics
- Saves best model in H5 format

Author: Bharat EV Saathi Project
Date: November 2025
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras import layers, models, callbacks
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import joblib
import json
import sys

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from backend.data_loader import ev_data

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Paths
PROJECT_ROOT = Path(__file__).parent.parent
MODEL_DIR = PROJECT_ROOT / 'models' / 'saved'
MODEL_DIR.mkdir(parents=True, exist_ok=True)

class AdvancedEVRecommender:
    """
    Advanced EV Recommendation System using Deep Neural Networks
    """
    
    def __init__(self):
        """Initialize the recommender"""
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.feature_columns = []
        self.num_classes = 0
        self.history = None
        print("‚úÖ Advanced EV Recommender initialized")
    
    def prepare_data(self):
        """
        Load and prepare data with advanced feature engineering
        
        Returns:
            Tuple of (X_train, X_val, X_test, y_train, y_val, y_test, df)
        """
        print("\nüìä Loading and preparing data...")
        
        # Load EV data
        df = ev_data.load_ev_vehicles().copy()
        print(f"   Loaded {len(df)} EV models")
        
        # Advanced Feature Engineering
        print("\nüîß Engineering features...")
        
        # 1. Price features
        df['price_category'] = pd.cut(
            df['price_inr'],
            bins=[0, 200000, 500000, 1500000, 5000000, float('inf')],
            labels=[0, 1, 2, 3, 4]  # Numeric labels
        ).astype(int)
        
        df['log_price'] = np.log1p(df['price_inr'])
        df['price_per_kwh'] = df['price_inr'] / (df['battery_kwh'] + 1)
        
        # 2. Range features
        df['range_category'] = pd.cut(
            df['range_km'],
            bins=[0, 100, 200, 300, 400, float('inf')],
            labels=[0, 1, 2, 3, 4]
        ).astype(int)
        
        df['range_per_charge'] = df['range_km'] / (df['charging_time'] + 0.1)
        
        # 3. Efficiency features
        df['value_score'] = (df['range_km'] / df['battery_kwh']) / (df['price_inr'] / 100000)
        df['efficiency_score'] = df['efficiency_km_per_kwh'] * df['range_km'] / 1000
        df['power_efficiency'] = df['battery_kwh'] / (df['charging_time'] + 0.1)
        
        # 4. Battery features
        df['battery_category'] = pd.cut(
            df['battery_kwh'],
            bins=[0, 5, 15, 30, 50, float('inf')],
            labels=[0, 1, 2, 3, 4]
        ).astype(int)
        
        df['battery_to_range_ratio'] = df['battery_kwh'] / (df['range_km'] + 1)
        
        # 5. Performance features
        df['speed_category'] = pd.cut(
            df['top_speed'],
            bins=[0, 60, 90, 120, 150, float('inf')],
            labels=[0, 1, 2, 3, 4]
        ).astype(int)
        
        df['performance_score'] = (df['top_speed'] / 10) + (df['range_km'] / 100)
        
        # 6. Charging features
        df['fast_charge'] = (df['battery_kwh'] > 10).astype(int)
        df['quick_charge'] = (df['charging_time'] < 5).astype(int)
        df['charging_speed'] = df['battery_kwh'] / (df['charging_time'] + 0.1)
        
        # 7. Segment features
        df['is_premium'] = df['segment'].str.contains('Premium|Luxury', case=False, na=False).astype(int)
        df['is_budget'] = df['segment'].str.contains('Budget|Affordable', case=False, na=False).astype(int)
        
        # 8. Type encoding
        type_encoder = LabelEncoder()
        df['type_encoded'] = type_encoder.fit_transform(df['type'])
        
        # 9. FAME features
        df['fame_encoded'] = (df['fame_eligible'] == 'Yes').astype(int)
        df['subsidy_ratio'] = df['central_subsidy_inr'] / (df['price_inr'] + 1)
        
        # 10. Rating features
        df['rating_score'] = df.get('user_rating', 4.0) / 5.0
        df['high_rated'] = (df.get('user_rating', 0) >= 4.0).astype(int)
        
        # 11. Composite scores
        df['overall_score'] = (
            df['value_score'] * 0.3 +
            df['efficiency_score'] * 0.25 +
            df['performance_score'] * 0.2 +
            df['rating_score'] * 100 * 0.15 +
            df['range_category'] * 10 * 0.1
        )
        
        # Create target variable (for classification)
        df['vehicle_class'] = df['brand'] + '_' + df['model'].str.replace(' ', '_')
        
        # Select features for the model (30+ features)
        feature_cols = [
            # Basic features
            'price_inr', 'range_km', 'battery_kwh', 'top_speed', 
            'charging_time', 'efficiency_km_per_kwh', 'seating_capacity',
            
            # Price features
            'price_category', 'log_price', 'price_per_kwh',
            
            # Range features
            'range_category', 'range_per_charge',
            
            # Efficiency features
            'value_score', 'efficiency_score', 'power_efficiency',
            
            # Battery features
            'battery_category', 'battery_to_range_ratio',
            
            # Performance features
            'speed_category', 'performance_score',
            
            # Charging features
            'fast_charge', 'quick_charge', 'charging_speed',
            
            # Segment features
            'is_premium', 'is_budget', 'type_encoded',
            
            # FAME features
            'fame_encoded', 'subsidy_ratio',
            
            # Rating features
            'rating_score', 'high_rated',
            
            # Composite
            'overall_score'
        ]
        
        self.feature_columns = feature_cols
        
        # Prepare X and y
        X = df[feature_cols].fillna(0).values
        y = df['vehicle_class']
        
        # Encode target
        y_encoded = self.label_encoder.fit_transform(y)
        self.num_classes = len(self.label_encoder.classes_)
        
        print(f"   ‚úÖ {len(feature_cols)} features engineered")
        print(f"   ‚úÖ {self.num_classes} vehicle classes")
        
        # Split data: 70% train, 15% validation, 15% test
        X_train_val, X_test, y_train_val, y_test = train_test_split(
            X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded
        )
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_val, y_train_val, test_size=0.176, random_state=42, stratify=y_train_val  # 0.176 of 0.85 ‚âà 0.15
        )
        
        # Scale features
        X_train = self.scaler.fit_transform(X_train)
        X_val = self.scaler.transform(X_val)
        X_test = self.scaler.transform(X_test)
        
        print(f"\nüìä Data split:")
        print(f"   Training:   {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)")
        print(f"   Validation: {len(X_val)} samples ({len(X_val)/len(X)*100:.1f}%)")
        print(f"   Testing:    {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)")
        
        return X_train, X_val, X_test, y_train, y_val, y_test, df
    
    def build_model(self, input_dim, num_classes):
        """
        Build an optimized deep neural network
        
        Args:
            input_dim: Number of input features
            num_classes: Number of output classes
            
        Returns:
            Compiled Keras model
        """
        print("\nüèóÔ∏è  Building neural network architecture...")
        
        model = models.Sequential([
            # Input layer with batch normalization
            layers.Dense(256, input_dim=input_dim),
            layers.BatchNormalization(),
            layers.Activation('relu'),
            layers.Dropout(0.3),
            
            # Hidden layer 1
            layers.Dense(128),
            layers.BatchNormalization(),
            layers.Activation('relu'),
            layers.Dropout(0.3),
            
            # Hidden layer 2
            layers.Dense(64),
            layers.BatchNormalization(),
            layers.Activation('relu'),
            layers.Dropout(0.2),
            
            # Hidden layer 3
            layers.Dense(32),
            layers.BatchNormalization(),
            layers.Activation('relu'),
            layers.Dropout(0.2),
            
            # Output layer
            layers.Dense(num_classes, activation='softmax')
        ])
        
        # Compile with optimal settings
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]
        )
        
        print(f"   ‚úÖ Model architecture:")
        print(f"      - Input: {input_dim} features")
        print(f"      - Hidden: [256 ‚Üí 128 ‚Üí 64 ‚Üí 32] neurons")
        print(f"      - Output: {num_classes} classes")
        print(f"      - Optimizer: Adam (lr=0.001)")
        print(f"      - Regularization: Dropout + BatchNorm")
        
        return model
    
    def train(self, epochs=150, batch_size=16):
        """
        Train the model with best practices
        
        Args:
            epochs: Number of training epochs
            batch_size: Batch size for training
            
        Returns:
            Training history and metrics
        """
        print("\n" + "="*60)
        print("üöÄ STARTING ADVANCED MODEL TRAINING")
        print("="*60)
        
        # Prepare data
        X_train, X_val, X_test, y_train, y_val, y_test, df = self.prepare_data()
        
        # Build model
        self.model = self.build_model(
            input_dim=len(self.feature_columns),
            num_classes=self.num_classes
        )
        
        # Print model summary
        print("\nüìã Model Summary:")
        self.model.summary()
        
        # Callbacks for training
        callbacks_list = [
            # Early stopping to prevent overfitting
            callbacks.EarlyStopping(
                monitor='val_accuracy',
                patience=20,
                restore_best_weights=True,
                verbose=1
            ),
            
            # Reduce learning rate when stuck
            callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=10,
                min_lr=0.00001,
                verbose=1
            ),
            
            # Save best model
            callbacks.ModelCheckpoint(
                str(MODEL_DIR / 'best_ev_model.h5'),
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            )
        ]
        
        print(f"\nüéØ Training configuration:")
        print(f"   Epochs: {epochs}")
        print(f"   Batch size: {batch_size}")
        print(f"   Callbacks: Early Stopping, LR Reduction, Model Checkpoint")
        
        print("\n" + "="*60)
        print("‚è≥ TRAINING IN PROGRESS...")
        print("="*60 + "\n")
        
        # Train the model
        self.history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks_list,
            verbose=1
        )
        
        print("\n" + "="*60)
        print("‚úÖ TRAINING COMPLETE!")
        print("="*60)
        
        # Evaluate on test set
        print("\nüìä Final Evaluation on Test Set:")
        test_loss, test_accuracy, test_top3_acc = self.model.evaluate(X_test, y_test, verbose=0)
        
        print(f"\nüéØ Final Metrics:")
        print(f"   Test Loss:        {test_loss:.4f}")
        print(f"   Test Accuracy:    {test_accuracy*100:.2f}%")
        print(f"   Top-3 Accuracy:   {test_top3_acc*100:.2f}%")
        
        # Get best validation accuracy from history
        best_val_acc = max(self.history.history['val_accuracy'])
        best_epoch = self.history.history['val_accuracy'].index(best_val_acc) + 1
        
        print(f"\nüèÜ Best Performance:")
        print(f"   Best Val Accuracy: {best_val_acc*100:.2f}%")
        print(f"   Best Epoch:        {best_epoch}/{len(self.history.history['val_accuracy'])}")
        
        # Detailed classification report
        print("\nüìà Detailed Classification Report:")
        y_pred = self.model.predict(X_test, verbose=0)
        y_pred_classes = np.argmax(y_pred, axis=1)
        
        # Top-5 predicted classes
        unique, counts = np.unique(y_pred_classes, return_counts=True)
        top_predicted = sorted(zip(unique, counts), key=lambda x: x[1], reverse=True)[:5]
        
        print(f"\n   Top 5 Predicted Classes:")
        for cls, count in top_predicted:
            class_name = self.label_encoder.inverse_transform([cls])[0]
            print(f"      {class_name}: {count} predictions")
        
        # Save metrics
        metrics = {
            'test_accuracy': float(test_accuracy),
            'test_loss': float(test_loss),
            'test_top3_accuracy': float(test_top3_acc),
            'best_val_accuracy': float(best_val_acc),
            'best_epoch': int(best_epoch),
            'total_epochs': len(self.history.history['val_accuracy']),
            'num_features': len(self.feature_columns),
            'num_classes': self.num_classes,
            'training_samples': len(X_train),
            'validation_samples': len(X_val),
            'test_samples': len(X_test)
        }
        
        return metrics
    
    def save_model(self):
        """Save the complete model and preprocessing objects"""
        print("\nüíæ Saving model and artifacts...")
        
        # Save H5 model
        model_path = MODEL_DIR / 'ev_recommender_model.h5'
        self.model.save(str(model_path))
        print(f"   ‚úÖ Model saved: {model_path}")
        
        # Save scaler
        scaler_path = MODEL_DIR / 'scaler.pkl'
        joblib.dump(self.scaler, str(scaler_path))
        print(f"   ‚úÖ Scaler saved: {scaler_path}")
        
        # Save label encoder
        encoder_path = MODEL_DIR / 'label_encoder.pkl'
        joblib.dump(self.label_encoder, str(encoder_path))
        print(f"   ‚úÖ Label encoder saved: {encoder_path}")
        
        # Save feature columns
        features_path = MODEL_DIR / 'feature_columns.json'
        with open(features_path, 'w') as f:
            json.dump({'features': self.feature_columns}, f, indent=2)
        print(f"   ‚úÖ Features saved: {features_path}")
        
        # Save training history
        if self.history:
            history_path = MODEL_DIR / 'training_history.json'
            history_dict = {key: [float(val) for val in values] 
                          for key, values in self.history.history.items()}
            with open(history_path, 'w') as f:
                json.dump(history_dict, f, indent=2)
            print(f"   ‚úÖ History saved: {history_path}")
        
        print(f"\n‚úÖ All artifacts saved to: {MODEL_DIR}")
    
    def plot_training_history(self):
        """Plot training history"""
        if not self.history:
            print("‚ö†Ô∏è  No training history available")
            return
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        # Accuracy plot
        axes[0].plot(self.history.history['accuracy'], label='Train Accuracy')
        axes[0].plot(self.history.history['val_accuracy'], label='Val Accuracy')
        axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Accuracy')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # Loss plot
        axes[1].plot(self.history.history['loss'], label='Train Loss')
        axes[1].plot(self.history.history['val_loss'], label='Val Loss')
        axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Loss')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Save plot
        plot_path = MODEL_DIR / 'training_history.png'
        plt.savefig(str(plot_path), dpi=300, bbox_inches='tight')
        print(f"\nüìä Training plots saved: {plot_path}")
        
        plt.close()


def main():
    """Main training function"""
    print("\n" + "="*60)
    print("üöó‚ö° BHARAT EV SAATHI - MODEL TRAINING")
    print("="*60)
    print("Advanced Deep Learning Model for EV Recommendations")
    print("="*60 + "\n")
    
    # Initialize recommender
    recommender = AdvancedEVRecommender()
    
    # Train model
    metrics = recommender.train(epochs=150, batch_size=16)
    
    # Save everything
    recommender.save_model()
    
    # Plot training history
    recommender.plot_training_history()
    
    # Final summary
    print("\n" + "="*60)
    print("üéâ MODEL TRAINING COMPLETE!")
    print("="*60)
    print(f"\nüìä Final Summary:")
    print(f"   Test Accuracy:     {metrics['test_accuracy']*100:.2f}%")
    print(f"   Top-3 Accuracy:    {metrics['test_top3_accuracy']*100:.2f}%")
    print(f"   Best Val Accuracy: {metrics['best_val_accuracy']*100:.2f}%")
    print(f"   Total Epochs:      {metrics['total_epochs']}")
    print(f"   Features Used:     {metrics['num_features']}")
    print(f"   Vehicle Classes:   {metrics['num_classes']}")
    
    print(f"\n‚úÖ Model saved as: ev_recommender_model.h5")
    print(f"‚úÖ Location: {MODEL_DIR}")
    
    print("\n" + "="*60)
    print("üöÄ Ready for deployment!")
    print("="*60 + "\n")


if __name__ == '__main__':
    main()
